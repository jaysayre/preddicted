{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import os\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dir = \"/home/j/Dropbox/College/Data Science/Project/intelligent-dolphins/Data/\" #Fill in your own\n",
      "\n",
      "path, dirs, files = os.walk(file_dir).next()\n",
      "csvfiles = [file_dir + i for i in files if \".csv\" in i ] #Builds a list with .csv files\n",
      "csvfiles.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csvfiles[13]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "'/home/j/Dropbox/College/Data Science/Project/intelligent-dolphins/Data/explainlikeimfivetop_all.csv'"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(csvfiles[13], encoding='utf-8') # Top all is our training data set\n",
      "df2 = pd.read_csv(csvfiles[14], encoding='utf-8') # Top week is our test data set\n",
      "df['up/down'] = df['upvotes'].astype(float)/df['downvotes'].astype(float) # Reddit fuzzes this so... \n",
      "df2['up/down'] = df2['upvotes'].astype(float)/df2['downvotes'].astype(float)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So apparently the strings in odd places problem isn't quite solved yet, see AskReddittopall..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df=df[df['comments'].apply(lambda x: isinstance(x, basestring) == False)] \n",
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author</th>\n",
        "      <th>comments</th>\n",
        "      <th>downvotes</th>\n",
        "      <th>id</th>\n",
        "      <th>score</th>\n",
        "      <th>selftext</th>\n",
        "      <th>title</th>\n",
        "      <th>upvotes</th>\n",
        "      <th>up/down</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>432</th>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 108,
       "text": [
        "    author comments  downvotes   id  score selftext title  upvotes  up/down\n",
        "432    NaN      NaN        NaN  NaN    NaN      NaN   NaN      NaN      NaN"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topcomments=float(max(df['comments']))\n",
      "topsscore=float(max(df['score']))\n",
      "leastcontro = max(df['up/down'])\n",
      "# This needs to be improved. Sticking with it simply for testing purposes\n",
      "df['mymetric'] = (((df['comments'].astype(float)/topcomments)*0.10)+((df['score'].astype(float)/topsscore)*0.85)+((df['up/down']/leastcontro)*0.05))**(0.30)\n",
      "df['nrmscore'] = (df['score'].astype(float)/topsscore)**(0.30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topcomments=float(max(df2['comments']))\n",
      "topsscore=float(max(df2['score']))\n",
      "leastcontro = max(df2['up/down'])\n",
      "# This needs to be improved. Sticking with it simply for testing purposes\n",
      "df2['mymetric'] = (((df2['comments'].astype(float)/topcomments)*0.10)+((df2['score'].astype(float)/topsscore)*0.85)+((df2['up/down']/leastcontro)*0.05))\n",
      "df2['nrmscore'] = df2['score'].astype(float)/topsscore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['nrmscore']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "0     1.000000\n",
        "1     0.956085\n",
        "2     0.934525\n",
        "3     0.913486\n",
        "4     0.911298\n",
        "5     0.909207\n",
        "6     0.903314\n",
        "7     0.902529\n",
        "8     0.895392\n",
        "9     0.894934\n",
        "10    0.890790\n",
        "11    0.890442\n",
        "12    0.888468\n",
        "13    0.885663\n",
        "14    0.885546\n",
        "...\n",
        "961    0.542837\n",
        "962    0.543571\n",
        "963    0.542100\n",
        "964    0.542469\n",
        "965    0.539877\n",
        "966    0.542100\n",
        "967    0.541731\n",
        "968    0.540620\n",
        "969    0.540991\n",
        "970    0.540991\n",
        "971    0.539131\n",
        "972    0.541362\n",
        "973    0.541362\n",
        "974    0.539877\n",
        "975    0.538757\n",
        "Name: nrmscore, Length: 968, dtype: float64"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So a few things about the way Reddit generates its metrics. First, I highly encourage that you read [this article on how Reddit ranks posts](http://amix.dk/blog/post/19588). Second, Reddit \"fuzzes\" the upvotes and downvotes so spambots can't manipulate the forum easily, so while the score is accurate, the number of upvotes and downvotes is not. For reference, $score = upvotes - downvotes$. Therefore, it must be that reddit adds/subtracts some unknown constant $k$ to the number of upvotes and downvotes.\n",
      "\n",
      "Currently, I've simply computed up/down as a measure of whether or not a post is controversial, but mathematically we may want to talk about methods to try to normalize this figure (if such a method exists).\n",
      "\n",
      "Third, I've found the actual paper that the Stanford researchers produced, and [it's worth a read over](http://i.stanford.edu/~julian/pdfs/icwsm13.pdf)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#It's important in cross validation that the sets are disjoint, so we are removing duplicates\n",
      "dfids = list(df['id'])\n",
      "df2ids = list(df2['id'])\n",
      "\n",
      "dupids = []\n",
      "for redditid in dfids:\n",
      "    if redditid in df2ids:\n",
      "        dupids.append(redditid)\n",
      "\n",
      "#This part is slightly overengineered, but the motivation behind it is that we didn't want to simply strip out the \n",
      "#posts from other data set at will. Instead, we are splitting the duplicates in half and assigning them to one of the data sets\n",
      "#to avoid some sort of possible bias.\n",
      "if len(dupids)%2 != 0:\n",
      "    a = len(dupids)/2\n",
      "    a = a+1\n",
      "    dup1 = dupids[0:a]\n",
      "    dup2 = dupids[a:]\n",
      "else: \n",
      "    a = len(dupids)/2\n",
      "    dup1 = dupids[0:a]\n",
      "    dup2 = dupids[a:]\n",
      "    \n",
      "if np.random.randint(2) == 0:\n",
      "    df=df[df['id'].apply(lambda x: x in dup1) == False]\n",
      "    df2=df2[df2['id'].apply(lambda x: x in dup2) == False]\n",
      "else: \n",
      "    df=df[df['id'].apply(lambda x: x in dup2) == False]\n",
      "    df2=df2[df2['id'].apply(lambda x: x in dup1) == False]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author</th>\n",
        "      <th>comments</th>\n",
        "      <th>downvotes</th>\n",
        "      <th>id</th>\n",
        "      <th>score</th>\n",
        "      <th>selftext</th>\n",
        "      <th>title</th>\n",
        "      <th>upvotes</th>\n",
        "      <th>up/down</th>\n",
        "      <th>mymetric</th>\n",
        "      <th>nrmscore</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>         TheeGing3</td>\n",
        "      <td> 4253</td>\n",
        "      <td> 2491</td>\n",
        "      <td>  vb8vs</td>\n",
        "      <td> 3395</td>\n",
        "      <td> I understand what medicare is and everything b...</td>\n",
        "      <td> ELI5: What exactly is Obamacare and what did i...</td>\n",
        "      <td> 5886</td>\n",
        "      <td> 2.362906</td>\n",
        "      <td> 0.961102</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>             32082</td>\n",
        "      <td> 1740</td>\n",
        "      <td> 4988</td>\n",
        "      <td> 1o6vem</td>\n",
        "      <td> 2923</td>\n",
        "      <td> EDIT: Thanks for all the comments, there some ...</td>\n",
        "      <td> ELI5: Why does the enormous cost of the USA's ...</td>\n",
        "      <td> 7911</td>\n",
        "      <td> 1.586006</td>\n",
        "      <td> 0.780190</td>\n",
        "      <td> 0.860972</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>       OriginalJam</td>\n",
        "      <td> 1186</td>\n",
        "      <td> 3956</td>\n",
        "      <td> 1mkyva</td>\n",
        "      <td> 2709</td>\n",
        "      <td> It even seems like they know that the apprenti...</td>\n",
        "      <td> ELI5: If Sith Apprentices always kill the mast...</td>\n",
        "      <td> 6665</td>\n",
        "      <td> 1.684783</td>\n",
        "      <td> 0.714050</td>\n",
        "      <td> 0.797938</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> The_Pale_Blue_Dot</td>\n",
        "      <td>  440</td>\n",
        "      <td> 2873</td>\n",
        "      <td> 1qltjh</td>\n",
        "      <td> 2511</td>\n",
        "      <td> Of course, I know that one means \"Registered T...</td>\n",
        "      <td>          ELI5: The difference between \u00ae, \u00a9, and \u2122</td>\n",
        "      <td> 5384</td>\n",
        "      <td> 1.873999</td>\n",
        "      <td> 0.647825</td>\n",
        "      <td> 0.739617</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>      martyclarity</td>\n",
        "      <td>  890</td>\n",
        "      <td> 3554</td>\n",
        "      <td> 1pszv9</td>\n",
        "      <td> 2491</td>\n",
        "      <td> Which particular events or people, if any, act...</td>\n",
        "      <td> ELI5: Why did society's view of 'The Future' c...</td>\n",
        "      <td> 6045</td>\n",
        "      <td> 1.700900</td>\n",
        "      <td> 0.652585</td>\n",
        "      <td> 0.733726</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> clean-yes-germ-no</td>\n",
        "      <td> 1324</td>\n",
        "      <td> 2401</td>\n",
        "      <td> 1m1bxg</td>\n",
        "      <td> 2472</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> ELI5: Why is it that ready-to-eat whole BBQ ch...</td>\n",
        "      <td> 4873</td>\n",
        "      <td> 2.029571</td>\n",
        "      <td> 0.659577</td>\n",
        "      <td> 0.728130</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>     GhostsofDogma</td>\n",
        "      <td>  353</td>\n",
        "      <td> 2729</td>\n",
        "      <td> 1eweon</td>\n",
        "      <td> 2419</td>\n",
        "      <td> Questions here are supposed to be covering com...</td>\n",
        "      <td> [META] Okay, this sub is slowly turning into /...</td>\n",
        "      <td> 5148</td>\n",
        "      <td> 1.886405</td>\n",
        "      <td> 0.622804</td>\n",
        "      <td> 0.712518</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>         Niall1990</td>\n",
        "      <td> 1410</td>\n",
        "      <td> 2555</td>\n",
        "      <td> 1r6f8w</td>\n",
        "      <td> 2412</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> ELI5: Americans: What exactly happened to Detr...</td>\n",
        "      <td> 4967</td>\n",
        "      <td> 1.944031</td>\n",
        "      <td> 0.646175</td>\n",
        "      <td> 0.710457</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>         [deleted]</td>\n",
        "      <td> 1328</td>\n",
        "      <td> 2531</td>\n",
        "      <td> 1kvf1l</td>\n",
        "      <td> 2349</td>\n",
        "      <td> I have been wondering for a long time, but fel...</td>\n",
        "      <td>         ELI5: What does the One Ring actually do?</td>\n",
        "      <td> 4880</td>\n",
        "      <td> 1.928092</td>\n",
        "      <td> 0.628399</td>\n",
        "      <td> 0.691900</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>        sleeper141</td>\n",
        "      <td>  400</td>\n",
        "      <td> 2557</td>\n",
        "      <td> 16rnfn</td>\n",
        "      <td> 2345</td>\n",
        "      <td> I know this kind of breaks the rules, but I th...</td>\n",
        "      <td> ELI67 Please explain like I'm 67 the differenc...</td>\n",
        "      <td> 4902</td>\n",
        "      <td> 1.917090</td>\n",
        "      <td> 0.605526</td>\n",
        "      <td> 0.690722</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "              author  comments  downvotes      id  score  \\\n",
        "0          TheeGing3      4253       2491   vb8vs   3395   \n",
        "1              32082      1740       4988  1o6vem   2923   \n",
        "2        OriginalJam      1186       3956  1mkyva   2709   \n",
        "3  The_Pale_Blue_Dot       440       2873  1qltjh   2511   \n",
        "4       martyclarity       890       3554  1pszv9   2491   \n",
        "5  clean-yes-germ-no      1324       2401  1m1bxg   2472   \n",
        "6      GhostsofDogma       353       2729  1eweon   2419   \n",
        "7          Niall1990      1410       2555  1r6f8w   2412   \n",
        "8          [deleted]      1328       2531  1kvf1l   2349   \n",
        "9         sleeper141       400       2557  16rnfn   2345   \n",
        "\n",
        "                                            selftext  \\\n",
        "0  I understand what medicare is and everything b...   \n",
        "1  EDIT: Thanks for all the comments, there some ...   \n",
        "2  It even seems like they know that the apprenti...   \n",
        "3  Of course, I know that one means \"Registered T...   \n",
        "4  Which particular events or people, if any, act...   \n",
        "5                                                NaN   \n",
        "6  Questions here are supposed to be covering com...   \n",
        "7                                                NaN   \n",
        "8  I have been wondering for a long time, but fel...   \n",
        "9  I know this kind of breaks the rules, but I th...   \n",
        "\n",
        "                                               title  upvotes   up/down  \\\n",
        "0  ELI5: What exactly is Obamacare and what did i...     5886  2.362906   \n",
        "1  ELI5: Why does the enormous cost of the USA's ...     7911  1.586006   \n",
        "2  ELI5: If Sith Apprentices always kill the mast...     6665  1.684783   \n",
        "3           ELI5: The difference between \u00ae, \u00a9, and \u2122     5384  1.873999   \n",
        "4  ELI5: Why did society's view of 'The Future' c...     6045  1.700900   \n",
        "5  ELI5: Why is it that ready-to-eat whole BBQ ch...     4873  2.029571   \n",
        "6  [META] Okay, this sub is slowly turning into /...     5148  1.886405   \n",
        "7  ELI5: Americans: What exactly happened to Detr...     4967  1.944031   \n",
        "8          ELI5: What does the One Ring actually do?     4880  1.928092   \n",
        "9  ELI67 Please explain like I'm 67 the differenc...     4902  1.917090   \n",
        "\n",
        "   mymetric  nrmscore  \n",
        "0  0.961102  1.000000  \n",
        "1  0.780190  0.860972  \n",
        "2  0.714050  0.797938  \n",
        "3  0.647825  0.739617  \n",
        "4  0.652585  0.733726  \n",
        "5  0.659577  0.728130  \n",
        "6  0.622804  0.712518  \n",
        "7  0.646175  0.710457  \n",
        "8  0.628399  0.691900  \n",
        "9  0.605526  0.690722  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(min_df=0.001)\n",
      "title = df['title']\n",
      "vectorizer.fit(title)\n",
      "X = vectorizer.transform(title)\n",
      "Y = np.array(df['mymetric'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer2 = CountVectorizer(min_df=0.001)\n",
      "title2 = df2['title']\n",
      "vectorizer2.fit(title2)\n",
      "X2 = vectorizer2.transform(title2)\n",
      "Y2 = np.array(df2['score'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.5) #I added the train size parameter.\n",
      "\n",
      "clf = MultinomialNB(alpha=1)\n",
      "clf.fit(x_train, y_train)\n",
      "print \"Training accuracy is\", clf.score(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training accuracy is 0.981404958678\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Test accuracy is\", clf.score(x_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test accuracy is 0.0\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#words = vectorizer2.get_feature_names()\n",
      "#words\n",
      "#diag_words = np.eye(len(words))\n",
      "#probword = pd.DataFrame(clf.predict_proba(diag_words))\n",
      "#probword.rename(columns={0: 'rotten', 1: 'fresh'}, inplace=True)\n",
      "#probword['words'] = words\n",
      "#print \"Top 10 Rotten words are\"\n",
      "#probword.sort([3], ascending=False)\n",
      "#probword['words'].head(20)\n",
      "\n",
      "#print \"\\n Top 10 Fresh words are\"\n",
      "#print probword.sort(['fresh'], ascending=False)[0:10]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top 10 Rotten words are\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 330,
       "text": [
        "0            1st\n",
        "1             27\n",
        "2            360\n",
        "3          65534\n",
        "4             72\n",
        "5          about\n",
        "6          abuse\n",
        "7        account\n",
        "8     accountant\n",
        "9     accusation\n",
        "10         admin\n",
        "11         admit\n",
        "12         adobe\n",
        "13     adversity\n",
        "14         alike\n",
        "15           all\n",
        "16        almost\n",
        "17           alt\n",
        "18        always\n",
        "19    alzheimers\n",
        "Name: words, dtype: object"
       ]
      }
     ],
     "prompt_number": 330
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So while I have quite figured out how to get this to work properly, it's pretty obvious from doing a quick Naive Bayes fit that this method isn't going that work, regardless of what parameters we pick -- I don't really know though so you (whoever you are?) should fucking check me on this. It could work-- idk. Alternately, could just be this subreddit - I don't fucking know.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make sure to use your own API key\n",
      "apikey = \"dcac82649daaa2627ee783b25779cfaed4af0067\" #Jay's key\n",
      "#apikey = \"e945cef59338f9e8e7bc962badde170e623fb7e5\" #Basti's key\n",
      "#apikey = \"cb736ca44e57cd6764b70ec86886f4fce8f6a68d\" #Serguei's Key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from myalchemy import MyAlchemy\n",
      "p= MyAlchemy(apikey)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dftitles = list(df['title'])\n",
      "df2titles = list(df2['title'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dftitles[5]\n",
      "print p.run_method(dftitles[5], 'concepts')\n",
      "print p.run_method(dftitles[5], 'keywords')\n",
      "print p.run_method(dftitles[5], 'category')\n",
      "print p.run_method(dftitles[5], 'sentiment')\n",
      "#print p.run_method(dftitles[5], 'entities')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ELI5: Why is it that ready-to-eat whole BBQ chickens at the grocery store are cheaper than whole raw chickens.\n",
        "[(u'0.91136', u'Grocery store'), (u'0.8704', u'Safeway Inc.')]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(u'0.980302', u'BBQ chickens'), (u'0.757824', u'raw chickens'), (u'0.588539', u'grocery store')]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'business', u'english', u'0.407783', u'OK')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'-0.344499', u'negative')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Concepts, keywords, category, sentiment, entities\n",
      "\n",
      "categories = []\n",
      "#for i in range(len(dftitles)):\n",
      "for i in range(4, 30):\n",
      "    categories.append(p.run_method(dftitles[i], 'category')[0])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 395
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 396,
       "text": [
        "[u'arts_entertainment',\n",
        " u'business',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'computer_internet',\n",
        " u'arts_entertainment',\n",
        " u'unknown',\n",
        " u'computer_internet',\n",
        " u'unknown',\n",
        " u'arts_entertainment',\n",
        " u'arts_entertainment',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'science_technology',\n",
        " u'health',\n",
        " u'unknown',\n",
        " u'science_technology',\n",
        " u'health',\n",
        " u'arts_entertainment',\n",
        " u'unknown']"
       ]
      }
     ],
     "prompt_number": 396
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see here that perhaps just using the titles might not give us enough information to accurately ascertain what the posts are about."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_comments(subreddit, postid, sort_call, user_agent):\n",
      "    '''\n",
      "    Parameters --\n",
      "    subreddit: subreddit title\n",
      "    postid: 6 digit id corresponding to the post\n",
      "    sort_call: one of confidence, top, new, hot, controversial, old, random\n",
      "    user_agent: same as before\n",
      "    \n",
      "    Returns --\n",
      "    '''\n",
      "    reddit_base = 'http://www.reddit.com/r/%s/comments/%s.json?' % (subreddit, postid) \n",
      "    headers = {'User-agent': user_agent}\n",
      "    post_params = {'sort': sort_call}\n",
      "    jsondata = json_extract(reddit_base, headers, post_params)\n",
      "    comments, ids, ups, downs, authors, distin = [], [], [], [], [], []\n",
      "    for item in jsondata[1]['data']['children']:\n",
      "        for key, value in item['data'].items():\n",
      "            if key == \"author\":\n",
      "                if value == None:\n",
      "                    authors.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    authors.append('null')\n",
      "                else:\n",
      "                    authors.append(value)\n",
      "                    \n",
      "            elif key == \"id\":\n",
      "                if value == None:\n",
      "                    ids.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    ids.append('null')\n",
      "                else:\n",
      "                    ids.append(str(value))\n",
      "            elif key == \"body\":\n",
      "                if value == None:\n",
      "                    comments.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    comments.append('null')\n",
      "                else:\n",
      "                    comments.append(value)#.replace('\\n', ''))\n",
      "            elif key == \"ups\":\n",
      "                if value == None:\n",
      "                    ups.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    ups.append('null')\n",
      "                else:\n",
      "                    ups.append(value)\n",
      "            elif key == \"downs\":\n",
      "                if value == None:\n",
      "                    downs.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    downs.append('null')\n",
      "                else:\n",
      "                    downs.append(value)\n",
      "            elif key == \"distinguished\":\n",
      "                if value == None:\n",
      "                    distin.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    distin.append('null')\n",
      "                else:\n",
      "                    distin.append(value)\n",
      "            else:\n",
      "                pass\n",
      "    \n",
      "    ids.pop(0)\n",
      "    datadict = {'comment': comments, 'id': ids, 'ups': ups, 'downs': downs, 'author': authors, 'distinguished': distin}\n",
      "    return pd.DataFrame(datadict)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def json_extract(baseurl, headrs=None, params=None, extraparam=None):\n",
      "    '''\n",
      "    Helper function to download and read json data. Takes in explanatory headers and returns json dict.\n",
      "    '''\n",
      "    if params != None:\n",
      "        if extraparam != None:\n",
      "                params['t'] = extraparam\n",
      "        form = urllib.urlencode(params)\n",
      "        url = baseurl+form\n",
      "    else:\n",
      "        url = baseurl\n",
      "    if headrs != None:\n",
      "        request = urllib2.Request(url, headers=headrs)\n",
      "    else: \n",
      "        request = urllib2.Request(url)\n",
      "    return json.loads(urllib2.urlopen(request).read())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import urllib2\n",
      "\n",
      "subreddit = 'explainlikeimfive'\n",
      "user_agent = (\"Project for Data Science class v1.0\" \" /u/Valedra\" \" https://github.com/jaysayre/intelligentdolphins\")\n",
      "\n",
      "topids = list(df['id'])\n",
      "\n",
      "endat = 150\n",
      "commentlen = []\n",
      "#for topid in topids:\n",
      "for i in range(endat):\n",
      "    try:\n",
      "        commentlen.append(len(list(get_comments(subreddit, topids[i], 'top', user_agent)['comment'])[0]))\n",
      "    except:\n",
      "        print topids[i]\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15u5d0\n",
        "s8l4e"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topids.index('15u5d0')\n",
      "topids.index('s8l4e')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "122"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(commentlen)\n",
      "\n",
      "topscores = list(df['score'])[:50] + list(df['score'])[51:122] + list(df['score'])[123:endat]\n",
      "topmetrics = list(df['mymetric'])[:50] + list(df['mymetric'])[51:122] + list(df['mymetric'])[123:endat]\n",
      "topups = list(df['upvotes'])[:50] + list(df['upvotes'])[51:122] + list(df['upvotes'])[123:endat]\n",
      "topcont = list(df['up/down'])[:50] + list(df['up/down'])[51:122] + list(df['up/down'])[123:endat]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "148\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There appears to be some minor correlation between the length of the top comment and popularity of the post, but it appears like this effect is on the decline over time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.stats import pearsonr\n",
      "\n",
      "print pearsonr(commentlen, topscores)\n",
      "print pearsonr(commentlen, topmetrics)\n",
      "print pearsonr(commentlen, topups)\n",
      "print pearsonr(commentlen, topcont)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.44383859210747884, 1.6035273359197743e-08)\n",
        "(0.44319470358692481, 1.6912587281428895e-08)\n",
        "(0.25094344719532163, 0.0020954876387472149)\n",
        "(0.041284452559721747, 0.61834237353945753)\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}