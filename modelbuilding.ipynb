{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import os\n",
      "import numpy as np\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dir = \"Data/\" #Fill in your own\n",
      "\n",
      "path, dirs, files = os.walk(file_dir).next()\n",
      "csvfiles = [file_dir + i for i in files if \".csv\" in i ] #Builds a list with .csv files\n",
      "csvfiles.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csvfiles[15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'Data/asksciencetop_week.csv'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(csvfiles[13], encoding='utf-8') # Top all is our training data set\n",
      "df2 = pd.read_csv(csvfiles[15], encoding='utf-8') # Top week is our test data set\n",
      "df['up/down'] = df['upvotes'].astype(float)/df['downvotes'].astype(float) # Reddit fuzzes this so... \n",
      "df2['up/down'] = df2['upvotes'].astype(float)/df2['downvotes'].astype(float)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topcomments=float(max(df['comments']))\n",
      "topsscore=float(max(df['score']))\n",
      "leastcontro = max(df['up/down'])\n",
      "# This needs to be improved. Sticking with it simply for testing purposes\n",
      "df['mymetric'] = (((df['comments'].astype(float)/topcomments)*0.10)+((df['score'].astype(float)/topsscore)*0.85)+((df['up/down']/leastcontro)*0.05))**(0.30)\n",
      "df['nrmscore'] = (df['score'].astype(float)/topsscore)**(0.30)\n",
      "print topcomments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2442.0\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topcomments=float(max(df2['comments']))\n",
      "topsscore=float(max(df2['score']))\n",
      "leastcontro = max(df2['up/down'])\n",
      "# This needs to be improved. Sticking with it simply for testing purposes\n",
      "df2['mymetric'] = (((df2['comments'].astype(float)/topcomments)*0.10)+((df2['score'].astype(float)/topsscore)*0.85)+((df2['up/down']/leastcontro)*0.05))\n",
      "df2['nrmscore'] = df2['score'].astype(float)/topsscore\n",
      "print topcomments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "774.0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So a few things about the way Reddit generates its metrics. First, I highly encourage that you read [this article on how Reddit ranks posts](http://amix.dk/blog/post/19588). Second, Reddit \"fuzzes\" the upvotes and downvotes so spambots can't manipulate the forum easily, so while the score is accurate, the number of upvotes and downvotes is not. For reference, $score = upvotes - downvotes$. Therefore, it must be that reddit adds/subtracts some unknown constant $k$ to the number of upvotes and downvotes.\n",
      "\n",
      "Currently, I've simply computed up/down as a measure of whether or not a post is controversial, but mathematically we may want to talk about methods to try to normalize this figure (if such a method exists).\n",
      "\n",
      "Third, I've found the actual paper that the Stanford researchers produced, and [it's worth a read over](http://i.stanford.edu/~julian/pdfs/icwsm13.pdf)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#It's important in cross validation that the sets are disjoint, so we are removing duplicates\n",
      "dfids = list(df['id'])\n",
      "df2ids = list(df2['id'])\n",
      "\n",
      "dupids = []\n",
      "for redditid in dfids:\n",
      "    if redditid in df2ids:\n",
      "        dupids.append(redditid)\n",
      "\n",
      "#This part is slightly overengineered, but the motivation behind it is that we didn't want to simply strip out the \n",
      "#posts from other data set at will. Instead, we are splitting the duplicates in half and assigning them to one of the data sets\n",
      "#to avoid some sort of possible bias.\n",
      "if len(dupids)%2 != 0:\n",
      "    a = len(dupids)/2\n",
      "    a = a+1\n",
      "    dup1 = dupids[0:a]\n",
      "    dup2 = dupids[a:]\n",
      "else: \n",
      "    a = len(dupids)/2\n",
      "    dup1 = dupids[0:a]\n",
      "    dup2 = dupids[a:]\n",
      "    \n",
      "if np.random.randint(2) == 0:\n",
      "    df=df[df['id'].apply(lambda x: x in dup1) == False]\n",
      "    df2=df2[df2['id'].apply(lambda x: x in dup2) == False]\n",
      "else: \n",
      "    df=df[df['id'].apply(lambda x: x in dup2) == False]\n",
      "    df2=df2[df2['id'].apply(lambda x: x in dup1) == False]\n",
      "\n",
      "#df['mymetric'] = df['score'] + (df['comments'].astype(float)/2)*0.30 - ((df['up/down']/20)*(0.30))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author</th>\n",
        "      <th>comments</th>\n",
        "      <th>downvotes</th>\n",
        "      <th>id</th>\n",
        "      <th>score</th>\n",
        "      <th>selftext</th>\n",
        "      <th>title</th>\n",
        "      <th>upvotes</th>\n",
        "      <th>subreddit</th>\n",
        "      <th>up/down</th>\n",
        "      <th>mymetric</th>\n",
        "      <th>nrmscore</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>            nilhaus</td>\n",
        "      <td> 364</td>\n",
        "      <td> 3554</td>\n",
        "      <td> 15in05</td>\n",
        "      <td> 3230</td>\n",
        "      <td> Example I have huge bookshelves full of books ...</td>\n",
        "      <td> Why cant I list every book I know but I can te...</td>\n",
        "      <td> 6784</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 1.908835</td>\n",
        "      <td> 0.964570</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>            deleted</td>\n",
        "      <td> 492</td>\n",
        "      <td> 3034</td>\n",
        "      <td> 1mk7wt</td>\n",
        "      <td> 2583</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> Have we taken flying insects into space Do the...</td>\n",
        "      <td> 5617</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 1.851351</td>\n",
        "      <td> 0.906537</td>\n",
        "      <td> 0.935140</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>         calicoJill</td>\n",
        "      <td> 602</td>\n",
        "      <td> 2225</td>\n",
        "      <td> 11i9nv</td>\n",
        "      <td> 2560</td>\n",
        "      <td> If life has started more than once on Earth do...</td>\n",
        "      <td> Is absolutely every organism on Earth related ...</td>\n",
        "      <td> 4785</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 2.150562</td>\n",
        "      <td> 0.907241</td>\n",
        "      <td> 0.932634</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>             Ruiner</td>\n",
        "      <td> 770</td>\n",
        "      <td> 3932</td>\n",
        "      <td>  w0qgf</td>\n",
        "      <td> 2412</td>\n",
        "      <td> In a few hours we will have an official announ...</td>\n",
        "      <td>            The official Higgs announcement thread</td>\n",
        "      <td> 6344</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 1.613428</td>\n",
        "      <td> 0.892583</td>\n",
        "      <td> 0.916120</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> CriticalOfAllPosts</td>\n",
        "      <td> 340</td>\n",
        "      <td> 2720</td>\n",
        "      <td> 1o32gn</td>\n",
        "      <td> 2397</td>\n",
        "      <td>             Edit Wow terrific responses Thank you</td>\n",
        "      <td> If I steep two tea bags in hot water rather th...</td>\n",
        "      <td> 5117</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 1.881250</td>\n",
        "      <td> 0.885280</td>\n",
        "      <td> 0.914407</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>        JaseAndrews</td>\n",
        "      <td> 424</td>\n",
        "      <td> 2865</td>\n",
        "      <td> 1mbftz</td>\n",
        "      <td> 2327</td>\n",
        "      <td> Can for example an ant see things such as bact...</td>\n",
        "      <td> Can creatures that are small see even smaller ...</td>\n",
        "      <td> 5192</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 1.812216</td>\n",
        "      <td> 0.878940</td>\n",
        "      <td> 0.906313</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>       Coloneljesus</td>\n",
        "      <td> 299</td>\n",
        "      <td> 2143</td>\n",
        "      <td> 1894b8</td>\n",
        "      <td> 2306</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> Why is glass so chemically stable Why are ther...</td>\n",
        "      <td> 4449</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 2.076062</td>\n",
        "      <td> 0.875834</td>\n",
        "      <td> 0.903851</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>  BornAgainSkydiver</td>\n",
        "      <td> 561</td>\n",
        "      <td> 2558</td>\n",
        "      <td> 1hhzcn</td>\n",
        "      <td> 2264</td>\n",
        "      <td> We have domesticated dogs and they come in ver...</td>\n",
        "      <td> Why do we have different sized dogs but all th...</td>\n",
        "      <td> 4822</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 1.885066</td>\n",
        "      <td> 0.874808</td>\n",
        "      <td> 0.898881</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>     surrealreality</td>\n",
        "      <td> 397</td>\n",
        "      <td> 2180</td>\n",
        "      <td> 1n84ms</td>\n",
        "      <td> 2264</td>\n",
        "      <td> At the moment rd top post this month And th to...</td>\n",
        "      <td> The Mars rover found that Martian soil is comp...</td>\n",
        "      <td> 4444</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 2.038532</td>\n",
        "      <td> 0.872768</td>\n",
        "      <td> 0.898881</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>         rotgutbill</td>\n",
        "      <td> 146</td>\n",
        "      <td> 2036</td>\n",
        "      <td> 1k7wgq</td>\n",
        "      <td> 2240</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> If air is mostly nitrogen and dirt is mostly c...</td>\n",
        "      <td> 4276</td>\n",
        "      <td> askscience</td>\n",
        "      <td> 2.100196</td>\n",
        "      <td> 0.866162</td>\n",
        "      <td> 0.896012</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "               author  comments  downvotes      id  score  \\\n",
        "0             nilhaus       364       3554  15in05   3230   \n",
        "1             deleted       492       3034  1mk7wt   2583   \n",
        "2          calicoJill       602       2225  11i9nv   2560   \n",
        "3              Ruiner       770       3932   w0qgf   2412   \n",
        "4  CriticalOfAllPosts       340       2720  1o32gn   2397   \n",
        "5         JaseAndrews       424       2865  1mbftz   2327   \n",
        "6        Coloneljesus       299       2143  1894b8   2306   \n",
        "7   BornAgainSkydiver       561       2558  1hhzcn   2264   \n",
        "8      surrealreality       397       2180  1n84ms   2264   \n",
        "9          rotgutbill       146       2036  1k7wgq   2240   \n",
        "\n",
        "                                            selftext  \\\n",
        "0  Example I have huge bookshelves full of books ...   \n",
        "1                                                NaN   \n",
        "2  If life has started more than once on Earth do...   \n",
        "3  In a few hours we will have an official announ...   \n",
        "4              Edit Wow terrific responses Thank you   \n",
        "5  Can for example an ant see things such as bact...   \n",
        "6                                                NaN   \n",
        "7  We have domesticated dogs and they come in ver...   \n",
        "8  At the moment rd top post this month And th to...   \n",
        "9                                                NaN   \n",
        "\n",
        "                                               title  upvotes   subreddit  \\\n",
        "0  Why cant I list every book I know but I can te...     6784  askscience   \n",
        "1  Have we taken flying insects into space Do the...     5617  askscience   \n",
        "2  Is absolutely every organism on Earth related ...     4785  askscience   \n",
        "3             The official Higgs announcement thread     6344  askscience   \n",
        "4  If I steep two tea bags in hot water rather th...     5117  askscience   \n",
        "5  Can creatures that are small see even smaller ...     5192  askscience   \n",
        "6  Why is glass so chemically stable Why are ther...     4449  askscience   \n",
        "7  Why do we have different sized dogs but all th...     4822  askscience   \n",
        "8  The Mars rover found that Martian soil is comp...     4444  askscience   \n",
        "9  If air is mostly nitrogen and dirt is mostly c...     4276  askscience   \n",
        "\n",
        "    up/down  mymetric  nrmscore  \n",
        "0  1.908835  0.964570  1.000000  \n",
        "1  1.851351  0.906537  0.935140  \n",
        "2  2.150562  0.907241  0.932634  \n",
        "3  1.613428  0.892583  0.916120  \n",
        "4  1.881250  0.885280  0.914407  \n",
        "5  1.812216  0.878940  0.906313  \n",
        "6  2.076062  0.875834  0.903851  \n",
        "7  1.885066  0.874808  0.898881  \n",
        "8  2.038532  0.872768  0.898881  \n",
        "9  2.100196  0.866162  0.896012  "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(min_df=0.001)\n",
      "title = list(df['title']) + list(df2['title'])\n",
      "vectorizer.fit(title)\n",
      "\n",
      "def category(x, df, num=20):\n",
      "    size = len(df)\n",
      "    blocksize = size/num\n",
      "    for i in range(num):\n",
      "        blockmax = max(sorted(df['score'])[blocksize*i:blocksize*(i+1)])        \n",
      "        if x < blockmax:\n",
      "            return i+1\n",
      "    return num\n",
      "\n",
      "#scores = [category(i) for i in df2['score']]\n",
      "#print scores\n",
      "#X = vectorizer.transform(title)\n",
      "#Y = np.array(scores)\n",
      "x_train = vectorizer.transform(df['title'])\n",
      "x_test = vectorizer.transform(df2['title'])\n",
      "score = [20 for i in df['score']]\n",
      "score2 = [category(i, df2) for i in df2['score']]\n",
      "y_train = np.array(score)\n",
      "y_test = np.array(score2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer2 = CountVectorizer(min_df=0.001)\n",
      "title2 = df2['title']\n",
      "vectorizer2.fit(title2)\n",
      "X2 = vectorizer2.transform(title2)\n",
      "Y2 = np.array(df2['score'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.5) #I added the train size parameter.\n",
      "\n",
      "clf = MultinomialNB(alpha=1)\n",
      "clf.fit(x_train, y_train)\n",
      "print \"Training accuracy is\", clf.score(x_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training accuracy is "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Test accuracy is\", clf.score(x_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test accuracy is 0.0622009569378\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#words = vectorizer2.get_feature_names()\n",
      "#words\n",
      "#diag_words = np.eye(len(words))\n",
      "#probword = pd.DataFrame(clf.predict_proba(diag_words))\n",
      "#probword.rename(columns={0: 'rotten', 1: 'fresh'}, inplace=True)\n",
      "#probword['words'] = words\n",
      "#print \"Top 10 Rotten words are\"\n",
      "#probword.sort([3], ascending=False)\n",
      "#probword['words'].head(20)\n",
      "\n",
      "#print \"\\n Top 10 Fresh words are\"\n",
      "#print probword.sort(['fresh'], ascending=False)[0:10]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 455
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So while I have quite figured out how to get this to work properly, it's pretty obvious from doing a quick Naive Bayes fit that this method isn't going that work, regardless of what parameters we pick -- I don't really know though so you (whoever you are?) should fucking check me on this. It could work-- idk. Alternately, could just be this subreddit - I don't fucking know.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make sure to use your own API key\n",
      "apikey = \"dcac82649daaa2627ee783b25779cfaed4af0067\" #Jay's key\n",
      "#apikey = \"e945cef59338f9e8e7bc962badde170e623fb7e5\" #Basti's key\n",
      "#apikey = \"cb736ca44e57cd6764b70ec86886f4fce8f6a68d\" #Serguei's Key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from myalchemy import MyAlchemy\n",
      "p= MyAlchemy(apikey)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dftitles = list(df['title'])\n",
      "df2titles = list(df2['title'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dftitles[5]\n",
      "print p.run_method(dftitles[5], 'concepts')\n",
      "print p.run_method(dftitles[5], 'keywords')\n",
      "print p.run_method(dftitles[5], 'category')\n",
      "#print p.run_method(dftitles[5], 'sentiment')\n",
      "print p.run_method(dftitles[5], 'entities')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Can creatures that are small see even smaller creatures ie bacteria because they are closer in size\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[(u'0.934117', u'smaller creatures'), (u'0.701291', u'bacteria'), (u'0.530302', u'size')]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(u'unknown', u'english', u'0.400001', u'OK')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Concepts, keywords, category, sentiment, entities\n",
      "\n",
      "categories = []\n",
      "#for i in range(len(dftitles)):\n",
      "for i in range(4, 30):\n",
      "    categories.append(p.run_method(dftitles[i], 'category')[0])\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 395
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 396,
       "text": [
        "[u'arts_entertainment',\n",
        " u'business',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'computer_internet',\n",
        " u'arts_entertainment',\n",
        " u'unknown',\n",
        " u'computer_internet',\n",
        " u'unknown',\n",
        " u'arts_entertainment',\n",
        " u'arts_entertainment',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'unknown',\n",
        " u'science_technology',\n",
        " u'health',\n",
        " u'unknown',\n",
        " u'science_technology',\n",
        " u'health',\n",
        " u'arts_entertainment',\n",
        " u'unknown']"
       ]
      }
     ],
     "prompt_number": 396
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see here that perhaps just using the titles might not give us enough information to accurately ascertain what the posts are about."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_comments(subreddit, postid, sort_call, user_agent):\n",
      "    '''\n",
      "    Parameters --\n",
      "    subreddit: subreddit title\n",
      "    postid: 6 digit id corresponding to the post\n",
      "    sort_call: one of confidence, top, new, hot, controversial, old, random\n",
      "    user_agent: same as before\n",
      "    \n",
      "    Returns --\n",
      "    '''\n",
      "    reddit_base = 'http://www.reddit.com/r/%s/comments/%s.json?' % (subreddit, postid) \n",
      "    headers = {'User-agent': user_agent}\n",
      "    post_params = {'sort': sort_call}\n",
      "    jsondata = json_extract(reddit_base, headers, post_params)\n",
      "    comments, ids, ups, downs, authors, distin = [], [], [], [], [], []\n",
      "    for item in jsondata[1]['data']['children']:\n",
      "        for key, value in item['data'].items():\n",
      "            if key == \"author\":\n",
      "                if value == None:\n",
      "                    authors.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    authors.append('null')\n",
      "                else:\n",
      "                    authors.append(value)\n",
      "                    \n",
      "            elif key == \"id\":\n",
      "                if value == None:\n",
      "                    ids.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    ids.append('null')\n",
      "                else:\n",
      "                    ids.append(str(value))\n",
      "            elif key == \"body\":\n",
      "                if value == None:\n",
      "                    comments.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    comments.append('null')\n",
      "                else:\n",
      "                    comments.append(value)#.replace('\\n', ''))\n",
      "            elif key == \"ups\":\n",
      "                if value == None:\n",
      "                    ups.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    ups.append('null')\n",
      "                else:\n",
      "                    ups.append(value)\n",
      "            elif key == \"downs\":\n",
      "                if value == None:\n",
      "                    downs.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    downs.append('null')\n",
      "                else:\n",
      "                    downs.append(value)\n",
      "            elif key == \"distinguished\":\n",
      "                if value == None:\n",
      "                    distin.append('null')\n",
      "                elif value == '[deleted]':\n",
      "                    distin.append('null')\n",
      "                else:\n",
      "                    distin.append(value)\n",
      "            else:\n",
      "                pass\n",
      "    \n",
      "    ids.pop(0)\n",
      "    datadict = {'comment': comments, 'id': ids, 'ups': ups, 'downs': downs, 'author': authors, 'distinguished': distin}\n",
      "    return pd.DataFrame(datadict)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def json_extract(baseurl, headrs=None, params=None, extraparam=None):\n",
      "    '''\n",
      "    Helper function to download and read json data. Takes in explanatory headers and returns json dict.\n",
      "    '''\n",
      "    if params != None:\n",
      "        if extraparam != None:\n",
      "                params['t'] = extraparam\n",
      "        form = urllib.urlencode(params)\n",
      "        url = baseurl+form\n",
      "    else:\n",
      "        url = baseurl\n",
      "    if headrs != None:\n",
      "        request = urllib2.Request(url, headers=headrs)\n",
      "    else: \n",
      "        request = urllib2.Request(url)\n",
      "    return json.loads(urllib2.urlopen(request).read())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import urllib2\n",
      "\n",
      "subreddit = 'explainlikeimfive'\n",
      "user_agent = (\"Project for Data Science class v1.0\" \" /u/Valedra\" \" https://github.com/jaysayre/intelligentdolphins\")\n",
      "\n",
      "topids = list(df['id'])\n",
      "\n",
      "endat = 150\n",
      "commentlen = []\n",
      "#for topid in topids:\n",
      "for i in range(endat):\n",
      "    try:\n",
      "        commentlen.append(len(list(get_comments(subreddit, topids[i], 'top', user_agent)['comment'])[0]))\n",
      "    except:\n",
      "        print topids[i]\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15u5d0\n",
        "s8l4e"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topids.index('15u5d0')\n",
      "topids.index('s8l4e')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "122"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(commentlen)\n",
      "\n",
      "topscores = list(df['score'])[:50] + list(df['score'])[51:122] + list(df['score'])[123:endat]\n",
      "topmetrics = list(df['mymetric'])[:50] + list(df['mymetric'])[51:122] + list(df['mymetric'])[123:endat]\n",
      "topups = list(df['upvotes'])[:50] + list(df['upvotes'])[51:122] + list(df['upvotes'])[123:endat]\n",
      "topcont = list(df['up/down'])[:50] + list(df['up/down'])[51:122] + list(df['up/down'])[123:endat]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "148\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There appears to be some minor correlation between the length of the top comment and popularity of the post, but it appears like this effect is on the decline over time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.stats import pearsonr\n",
      "\n",
      "print pearsonr(commentlen, topscores)\n",
      "print pearsonr(commentlen, topmetrics)\n",
      "print pearsonr(commentlen, topups)\n",
      "print pearsonr(commentlen, topcont)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.44383859210747884, 1.6035273359197743e-08)\n",
        "(0.44319470358692481, 1.6912587281428895e-08)\n",
        "(0.25094344719532163, 0.0020954876387472149)\n",
        "(0.041284452559721747, 0.61834237353945753)\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#following code will create a counter dictionary will all keywords in titles for a single subreddit\n",
      "\n",
      "def get_keywords(subreddit):\n",
      "    returndict = Counter()\n",
      "    for a in subreddit.title:\n",
      "        keywords = p.run_method(a, 'keywords')\n",
      "        if keywords:\n",
      "            for b in keywords:\n",
      "                returndict[b[1]] = returndict[b[1]] + 1\n",
      "    return returndict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_keywords = get_keywords(pd.read_csv(csvfiles[13], encoding='utf-8'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnicodeEncodeError",
       "evalue": "'ascii' codec can't encode character u'\\xfe' in position 61: ordinal not in range(128)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-38-d70f96484ad9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-35-20ccc0388b59>\u001b[0m in \u001b[0;36mget_keywords\u001b[1;34m(subreddit)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mreturndict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keywords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/j/Dropbox/College/Data Science/Project/intelligent-dolphins/myalchemy.py\u001b[0m in \u001b[0;36mrun_method\u001b[1;34m(self, comment, whichtoget, otherparams)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mglobal\u001b[0m \u001b[0malchemybase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__look_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhichtoget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36murlencode\u001b[1;34m(query, doseq)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1326\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xfe' in position 61: ordinal not in range(128)"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}