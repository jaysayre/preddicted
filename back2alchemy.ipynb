{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import os\n",
      "import urllib\n",
      "import urllib2\n",
      "import numpy as np\n",
      "import nltk\n",
      "from myalchemy import MyAlchemy\n",
      "\n",
      "#apikey = \"dcac82649daaa2627ee783b25779cfaed4af0067\" #Jay's key\n",
      "apikey = \"e945cef59338f9e8e7bc962badde170e623fb7e5\" #Basti's key\n",
      "#apikey = \"cb736ca44e57cd6764b70ec86886f4fce8f6a68d\" #Serguei's Key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Since we only get so many Alchemy API calls, might as well not call\n",
      "#Alchemy on duplicate posts between subreddits. We'll merge these later.\n",
      "df = pd.read_csv('Data/full.csv', encoding='utf-8')\n",
      "\n",
      "print \"Original size of data set is\", len(df)\n",
      "df = df.drop_duplicates('id') # We only want unique post id entries, not to waste alchemy calls\n",
      "print \"Size of data set with only unique posts is\", len(df)\n",
      "subs = list(df['subreddit'].unique()) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original size of data set is 44261\n",
        "Size of data set with only unique posts is 25992\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_dir = \"Data/combinedcomments/\"\n",
      "\n",
      "path, dirs, files = os.walk(file_dir).next()\n",
      "csvfiles = [file_dir + i for i in files if \".csv\" in i ] #Builds a list with .csv files\n",
      "csvfiles.sort()\n",
      "#csvfiles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_null(x):\n",
      "    try:\n",
      "        np.isnan(x)\n",
      "        return False\n",
      "    except:\n",
      "        return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#for sub in subs:\n",
      "#    print sub\n",
      "#    smalldf = df[df['subreddit'] == sub]\n",
      "#    commentfile = ''\n",
      "#    for comb in csvfiles:\n",
      "#        if sub in comb:\n",
      "#            print comb\n",
      "\n",
      "\n",
      "subrequest = 'jokes'\n",
      "smalldf = df[df['subreddit'] == subrequest]\n",
      "smalldf['commenttext'] = smalldf['selftext'] # Initializes comment column\n",
      "smalldf['alchemy'] = smalldf['selftext']\n",
      "commentfile = ''\n",
      "for comb in csvfiles:\n",
      "    if subrequest in comb:\n",
      "        commentfile = comb\n",
      "commentdf = pd.read_csv(commentfile, encoding='utf-8')\n",
      "commentdf = commentdf.drop('type',1)\n",
      "commentdf = commentdf.drop_duplicates()\n",
      "commentdf = commentdf[commentdf['comment'].apply(lambda x: check_null(x))]\n",
      "smalldfids = list(smalldf.index)\n",
      "for sid in smalldfids:\n",
      "    iddf = commentdf[commentdf['post'] == smalldf['id'][sid]]\n",
      "    comments = list(iddf['comment'])\n",
      "    comments.append(smalldf['title'][sid])\n",
      "    if check_null(smalldf['selftext'][sid]):\n",
      "        comments.append(smalldf['selftext'][sid])\n",
      "    try:\n",
      "        comments = ' '.join(comments)\n",
      "        smalldf['commenttext'][sid] =  comments\n",
      "    except:\n",
      "        print comments\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = MyAlchemy(apikey)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smalldfids = list(smalldf.index)\n",
      "for sid in smalldfids:\n",
      "    try:\n",
      "        smalldf['alchemy'][sid] = p.run_method(smalldf['commenttext'][sid], 'keywords', {'keywordExtractMode':'strict'})\n",
      "    except:\n",
      "        smalldf['alchemy'][sid] = 'Null'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print hey + \"\\n\"\n",
      "#print p.run_method(hey, 'concepts')\n",
      "#print \"\\n\"\n",
      "smalldf['alchemy'][9] = p.run_method(hey, 'keywords', {'keywordExtractMode':'strict'})\n",
      "#print p.run_method(dftitles[5], 'category')\n",
      "#print p.run_method(dftitles[5], 'sentiment')\n",
      "#print p.run_method(dftitles[5], 'entities')\n",
      "#print p.run_method(reddit_base, 'urlkeywords')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Hey a clean politicallycorrect joke thats also funny  Thank you Couldnt he gain wealth from his wisdom now What man wants most desperately is usually his downfall Reminded me of a great one by Stewart Francis When I was young a genie came to visit me He said I could either have a good memory or a long penis I dont remember what I picked Im not sure I understand the punchline Aww yeah gtmy reaction httpwwwyoutubecomwatchvXOtkXJc Nice this is a great one Thats pretty good Well done  An angel appears at a faculty meeting  And tells the dean that in return for his unselfish and exemplary behavior the Lord will reward him with his choice of infinite wealth wisdom or beauty Without hesitating the dean selects infinite wisdomDone says the angel and disappears in a cloud of smoke and a bolt of lightning Now all heads turn toward the dean who sits surrounded by a faint halo of light At length one of his colleagues whispers Say somethingThe dean sighs and says I should have taken the money\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "smalldf.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>author</th>\n",
        "      <th>comments</th>\n",
        "      <th>downvotes</th>\n",
        "      <th>id</th>\n",
        "      <th>score</th>\n",
        "      <th>selftext</th>\n",
        "      <th>subreddit</th>\n",
        "      <th>time_created</th>\n",
        "      <th>title</th>\n",
        "      <th>type</th>\n",
        "      <th>upvotes</th>\n",
        "      <th>karma</th>\n",
        "      <th>link_karma</th>\n",
        "      <th>commenttext</th>\n",
        "      <th>alchemy</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> APPLEZACKS</td>\n",
        "      <td> 119</td>\n",
        "      <td> 675</td>\n",
        "      <td>  zc7em</td>\n",
        "      <td> 1388</td>\n",
        "      <td>  And tells the dean that in return for his uns...</td>\n",
        "      <td> jokes</td>\n",
        "      <td> 1346772067</td>\n",
        "      <td>            An angel appears at a faculty meeting</td>\n",
        "      <td> top_all</td>\n",
        "      <td> 2063</td>\n",
        "      <td> 172</td>\n",
        "      <td> 2256</td>\n",
        "      <td> Hey a clean politicallycorrect joke thats also...</td>\n",
        "      <td> [(0.939444, politicallycorrect joke thats), (0...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>      oplav</td>\n",
        "      <td>  23</td>\n",
        "      <td> 280</td>\n",
        "      <td> 1hfshp</td>\n",
        "      <td>  836</td>\n",
        "      <td> looking for a job as a detective They meet wit...</td>\n",
        "      <td> jokes</td>\n",
        "      <td> 1372700523</td>\n",
        "      <td>               blondes walk into a police station</td>\n",
        "      <td> top_all</td>\n",
        "      <td> 1116</td>\n",
        "      <td> 908</td>\n",
        "      <td> 3854</td>\n",
        "      <td> I definitely thought this was going to end wit...</td>\n",
        "      <td> [(0.912149, profile mug shot), (0.753862, poli...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td>   bohogirl</td>\n",
        "      <td>  72</td>\n",
        "      <td> 707</td>\n",
        "      <td> 1ajp7w</td>\n",
        "      <td> 1531</td>\n",
        "      <td> two engineers were biking acro  a university c...</td>\n",
        "      <td> jokes</td>\n",
        "      <td> 1363639786</td>\n",
        "      <td>                              engineers on a bike</td>\n",
        "      <td> top_all</td>\n",
        "      <td> 2238</td>\n",
        "      <td>   0</td>\n",
        "      <td>    1</td>\n",
        "      <td> Heard this one with  rednecks and a truck  I w...</td>\n",
        "      <td> [(0.914713, horn dogs tooSource), (0.823244, g...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58</th>\n",
        "      <td>      PBnJX</td>\n",
        "      <td>   2</td>\n",
        "      <td>  17</td>\n",
        "      <td> 1qu3ie</td>\n",
        "      <td>   24</td>\n",
        "      <td> What do you call the area between a womans vag...</td>\n",
        "      <td> jokes</td>\n",
        "      <td> 1384712615</td>\n",
        "      <td>                                            holes</td>\n",
        "      <td>     hot</td>\n",
        "      <td>   41</td>\n",
        "      <td>   0</td>\n",
        "      <td>    0</td>\n",
        "      <td> Watch out for Sand Crabs  How good is your FOR...</td>\n",
        "      <td> [(0.926827, womans vagina), (0.811014, Sand Cr...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>68</th>\n",
        "      <td>     kokain</td>\n",
        "      <td>   9</td>\n",
        "      <td>  88</td>\n",
        "      <td> 1r2g2x</td>\n",
        "      <td>  294</td>\n",
        "      <td> A man and a woman are sitting beside each othe...</td>\n",
        "      <td> jokes</td>\n",
        "      <td> 1384965499</td>\n",
        "      <td>  Im suffering from a very rare medical condition</td>\n",
        "      <td>     hot</td>\n",
        "      <td>  382</td>\n",
        "      <td>   0</td>\n",
        "      <td>    1</td>\n",
        "      <td> i m top rate Forgive me but I do not understan...</td>\n",
        "      <td> [(0.942854, rare medical condition), (0.787171...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "        author  comments  downvotes      id  score  \\\n",
        "9   APPLEZACKS       119        675   zc7em   1388   \n",
        "27       oplav        23        280  1hfshp    836   \n",
        "49    bohogirl        72        707  1ajp7w   1531   \n",
        "58       PBnJX         2         17  1qu3ie     24   \n",
        "68      kokain         9         88  1r2g2x    294   \n",
        "\n",
        "                                             selftext subreddit  time_created  \\\n",
        "9    And tells the dean that in return for his uns...     jokes    1346772067   \n",
        "27  looking for a job as a detective They meet wit...     jokes    1372700523   \n",
        "49  two engineers were biking acro  a university c...     jokes    1363639786   \n",
        "58  What do you call the area between a womans vag...     jokes    1384712615   \n",
        "68  A man and a woman are sitting beside each othe...     jokes    1384965499   \n",
        "\n",
        "                                               title     type  upvotes  karma  \\\n",
        "9              An angel appears at a faculty meeting  top_all     2063    172   \n",
        "27                blondes walk into a police station  top_all     1116    908   \n",
        "49                               engineers on a bike  top_all     2238      0   \n",
        "58                                             holes      hot       41      0   \n",
        "68   Im suffering from a very rare medical condition      hot      382      0   \n",
        "\n",
        "    link_karma                                        commenttext  \\\n",
        "9         2256  Hey a clean politicallycorrect joke thats also...   \n",
        "27        3854  I definitely thought this was going to end wit...   \n",
        "49           1  Heard this one with  rednecks and a truck  I w...   \n",
        "58           0  Watch out for Sand Crabs  How good is your FOR...   \n",
        "68           1  i m top rate Forgive me but I do not understan...   \n",
        "\n",
        "                                              alchemy  \n",
        "9   [(0.939444, politicallycorrect joke thats), (0...  \n",
        "27  [(0.912149, profile mug shot), (0.753862, poli...  \n",
        "49  [(0.914713, horn dogs tooSource), (0.823244, g...  \n",
        "58  [(0.926827, womans vagina), (0.811014, Sand Cr...  \n",
        "68  [(0.942854, rare medical condition), (0.787171...  "
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jokes = pd.DataFrame({'author':smalldf['author'],'id':smalldf['id'],'alchemy':smalldf['alchemy']})\n",
      "jokes.to_csv('Data/alchemy/jokes.csv', index=False, encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}