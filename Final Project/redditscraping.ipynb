{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import praw\n",
      "import pandas as pd\n",
      "import json\n",
      "import os\n",
      "import urllib\n",
      "import urllib2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_agent = (\"Project for Data Science class v1.0\" \"/u/Valedra\" \"https://github.com/jaysayre/intelligentdolphins\")\n",
      "r = praw.Reddit(user_agent=user_agent)\n",
      "api_call_limit = 1000 # Reddit API limits to 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def get_subreddit_df(subreddit, n=None, limit=100000):\n",
      "    '''\n",
      "Function to get the DataFrame of a subreddit\n",
      "subreddit : str - title of subreddit\n",
      "n : int - nuber of rows required in DF\n",
      "    '''\n",
      "    ids, title, upvts, downvts, authors, comments, score = [], [], [], [], [], [], []\n",
      "    subreddit = r.get_subreddit('explainlikeimfive', fetch=True)\n",
      "    sub = subreddit.get_top_from_all(limit=n)\n",
      "    calltracker = 0\n",
      "    for post in sub:\n",
      "        if calltracker < limit:\n",
      "            if post.distinguished == None: #Removes moderator comments, which we presumably don't want.\n",
      "                ids.append(post.id)\n",
      "                title.append(post.title)\n",
      "                upvts.append(post.ups)\n",
      "                downvts.append(post.downs)\n",
      "                authors.append(str(post.author))\n",
      "                comments.append(post.num_comments)\n",
      "                score.append(post.score)\n",
      "                calltracker += 1\n",
      "                    \n",
      "    return pd.DataFrame({'id': ids, 'post_title': title, 'upvotes': upvts,\\\n",
      "         'downvts': downvts, 'comments': comments, 'score': score, 'author': authors}) #, 'karma':athrkarma})\n",
      "\n",
      "def add_karma(df):\n",
      "    '''\n",
      "Adds in the karma score for every author, and returns the same df except with the new information.\n",
      "Not sure why this step takes so long, but unfortunately it does.\n",
      "    '''\n",
      "    authorkarma = []\n",
      "    for author in df['author']:\n",
      "        try:\n",
      "            redditauthor = r.get_redditor(author)\n",
      "            authorkarma.append(redditauthor.comment_karma)\n",
      "        except:\n",
      "            authorkarma.append(0)\n",
      "    df['karma'] = authorkarma\n",
      "    return df\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eli5top = get_subreddit_df('explainlikeimfive', n=25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add karma if you want....\n",
      "eli5top = add_karma(eli5top)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "23"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The \"n\" in the following function is the number of top level comments you want to get. By default, reddit only shows the first 200, you can expand it (look at the docs for praw). \n",
      "\n",
      "Another idea is to include comment karma per post or based on the subreddit instead of just total karma \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_comments(postid, n=5):\n",
      "    submission = r.get_submission(submission_id=postid)\n",
      "    # Flattens comments and replies \n",
      "    #flat_comments = praw.helpers.flatten_tree(submission.comments) \n",
      "    comments, ids, scores, authors, authorkarma = [], [], [], [], []\n",
      "    \n",
      "    for i in range(n):\n",
      "        try:\n",
      "            #print ' \\n Comment: ASD\"\"' + submission.comments[i].body + '\"\"'\n",
      "            comments.append(submission.comments[i].body)\n",
      "            #print \"Submission Id:\", submission.comments[i].id\n",
      "            ids.append(submission.comments[i].id)\n",
      "            #print \"Score:\", submission.comments[i].score\n",
      "            scores.append(submission.comments[i].score)\n",
      "            #print \"Author:\", submission.comments[i].author\n",
      "            authors.append(submission.comments[i].author)\n",
      "            #This part can take a while... may be wiser to fetch in seperate step\n",
      "            #print \"Author Karma:\", submission.comments[i].author.comment_karma\n",
      "            authorkarma.append(submission.comments[i].author.comment_karma)\n",
      "        except:\n",
      "            pass\n",
      "    datadict = {'comment': comments, 'id': ids, 'score': scores, 'author': authors, 'authorkarma:': authorkarma}\n",
      "    return pd.DataFrame(datadict)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topids = list(eli5top['id'])\n",
      "    \n",
      "comments = get_comments(topids[2], 2)\n",
      "\n",
      "comment_texts = list(comments['comment'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comments.score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "0    2882\n",
        "1     254\n",
        "Name: score, dtype: int64"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The alchemy SDK sucks so I rewrote things. In my humble opinion, this is much cleaner. We may want to implement this as a class, but it doesn't really matter.\n",
      "\n",
      "ENTITITES refers to indivuduals mentioned in the text. RELEVANCE is the relevance in the context. sentiment is the impact the individual has on the meaning of the text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make sure to use your own API key\n",
      "#apikey = \"dcac82649daaa2627ee783b25779cfaed4af0067\" #Jay's key\n",
      "apikey = \"e945cef59338f9e8e7bc962badde170e623fb7e5\" #Basti's key\n",
      "#apikey = \"cb736ca44e57cd6764b70ec86886f4fce8f6a68d\" #Serguei's Key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alchemybase = \"http://access.alchemyapi.com/calls/text/\"\n",
      "textkeywords = \"TextGetRankedKeywords\"\n",
      "textcategory = \"TextGetCategory\"\n",
      "textconcepts = \"TextGetRankedConcepts\"\n",
      "textsentiment = \"TextGetTextSentiment\"\n",
      "textentities = \"TextGetRankedNamedEntities\"\n",
      "#texttargetedsent = \"TextGetTargetedSentiment\"\n",
      "\n",
      "postparams = {\n",
      "    'apikey' : apikey,\n",
      "    'text' : comment_texts,\n",
      "    'outputMode' : 'json',\n",
      "    #'maxRetrieve' : 8, #If you want to limit responses\n",
      "    'showSourceText' : 0, # I believe this turns it off IIRC\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_json(url):\n",
      "    jsonrsp = urllib2.urlopen(url)\n",
      "    data = json.load(jsonrsp)\n",
      "    return data\n",
      "\n",
      "def get_url(postparams, whichtoget, otherparams=None):\n",
      "    form = urllib.urlencode(postparams)\n",
      "    keywordsurl = alchemybase + whichtoget + \"?\" + form\n",
      "    if otherparams != None:\n",
      "        otherform = urllib.urlencode(postparams)\n",
      "        keywordsurl = alchemybase + whichtoget + \"?\" + form + otherform \n",
      "    data = get_json(keywordsurl)\n",
      "    return data\n",
      "        \n",
      "def text_concepts(data):\n",
      "    for item in data['concepts']: \n",
      "        print item['dbpedia']\n",
      "        print item['relevance']\n",
      "        print item['text']\n",
      "        \n",
      "def text_category(data):\n",
      "    print data['category']\n",
      "    print data['language']\n",
      "    print data['score']\n",
      "    print data['status']\n",
      "    \n",
      "def text_keywords(data):\n",
      "    for item in data['keywords']: \n",
      "        print item['relevance']\n",
      "        print item['text']\n",
      "        \n",
      "def text_sentiment(data):\n",
      "    print data['docSentiment']['mixed']\n",
      "    print data['docSentiment']['score']\n",
      "    print data['docSentiment']['type']\n",
      "\n",
      "def text_entities(data):\n",
      "    for item in data['entities']:\n",
      "        print item['count']\n",
      "        print item['relevance']\n",
      "        print item['text']\n",
      "        print item['type']\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#text_concepts(get_url(postparams, textconcepts, {'linkedData': 1}))\n",
      "#text_keywords(get_url(postparams, textkeywords, {'keywordExtractMode' : 'strict'})) \n",
      "text_category(get_url(postparams, textcategory))\n",
      "#text_sentiment(get_url(postparams, textsentiment))\n",
      "#text_entities(get_url(postparams, textentities))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "arts_entertainment\n",
        "english\n",
        "0.549265\n",
        "OK\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}