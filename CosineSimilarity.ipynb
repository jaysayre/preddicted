{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy.stats import pearsonr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to increase the quality of our clustering algorithms we wanted to look at text similarity to calculate the k nearest neighbors of a text and look at their scores. A famous algorithm for calculating the similarity between text is the cosine-similarity. The tutorial from the following cell can be found [here](http://pyevolve.sourceforge.net/wordpress/?p=2497)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The tfidf_matrix[0:1] is the Scipy operation to get the first row of the sparse matrix and the resulting array is the Cosine Similarity between the first document with all documents in the set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from http://stackoverflow.com/questions/12787650/finding-the-index-of-n-biggest-elements-in-python-array-list-efficiently\n",
      "def f(a):\n",
      "    return np.argsort(a)[0][::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = (\n",
      "\"The sky is blue\",\n",
      "\"The sun is bright\",\n",
      "\"The sun in the sky is bright\",\n",
      "\"We can see the shining sun, the bright sun\"\n",
      ")\n",
      "tfidf_vectorizer = TfidfVectorizer()\n",
      "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
      "print tfidf_matrix.shape\n",
      "\n",
      "print cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
      "print f(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, 5)\n",
        "[[ 1.          0.48740306  0.80547084  0.27002114]]\n",
        "[0 2 1 3]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_table = pd.read_csv('Data/full.csv', encoding='utf-8')\n",
      "big_table = big_table.drop_duplicates('id')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_xy(titles, scores, vectorizer=None):\n",
      "    #Set default vecotrizer\n",
      "    if not vectorizer:\n",
      "        vectorizer = TfidfVectorizer()\n",
      "        \n",
      "    #Build the vocabulary by fitting the vectorizer to the list of quotes\n",
      "    #Convert into a bag-of-words and use a sparse array to save memory\n",
      "    x = vectorizer.fit_transform(titles)    \n",
      "    #x = x.tocsc()\n",
      "    #save into numpy array, and return everything\n",
      "    y = np.array(scores)\n",
      "    return x, y, vectorizer\n",
      "\n",
      "X,Y,vectorizer = make_xy(list(big_table['title']), big_table['score'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for a in enumerate(x):\n",
      "#    cosine_similarity(X[0:1], X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "closest_title_scores = {}\n",
      "i = 1\n",
      "for a in X:\n",
      "    vec = cosine_similarity(a, X)\n",
      "    sorted_vec = f(vec)\n",
      "    #print vec[0][sorted_vec[1]]\n",
      "    num = 0\n",
      "    already_printed = 0\n",
      "    closest_list = []\n",
      "    while already_printed < 10:    \n",
      "        try:\n",
      "            curr = big_table['title'][sorted_vec[num]]\n",
      "            sco = big_table['score'][sorted_vec[num]]\n",
      "            \n",
      "            closest_list.append((curr, sco, vec[0][sorted_vec[num]]))\n",
      "            #print vec[0][sorted_vec[num]]\n",
      "            #print already_printed, curr\n",
      "            #print \"with score\", sco\n",
      "            already_printed +=1\n",
      "        except:\n",
      "            #print vec[0][sorted_vec[num]]\n",
      "            pass\n",
      "        \n",
      "        num +=1\n",
      "    closest_title_scores[closest_list[0][0]] = closest_list[1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print big_table['title'][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(closest_title_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def knearest(title, k=7):\n",
      "    \"\"\"\n",
      "    Given a restaurant_id, dataframe, and database, get a sorted list of the\n",
      "    k most similar restaurants from the entire database.\n",
      "    \"\"\"\n",
      "    return closest_title_scores[title][:k]\n",
      "knearest(' a Democratic state senator resigned her seat rather than face a recall vote that could have cost her party control of the chamber')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[(u'At what age for a child does something stop being cute and precious',\n",
        "  1,\n",
        "  0.33593179634207548),\n",
        " (u'If it could go wrong it went wrong An angry customer I actually enjoyed helping',\n",
        "  377,\n",
        "  0.26363998924005239),\n",
        " (u'ELI Why dont locomotives wheels spin when pulling extremely heavy loads',\n",
        "  1,\n",
        "  0.22856529770814651),\n",
        " (u'How did Western Europe and the world measure the years before Christ came around',\n",
        "  6,\n",
        "  0.22223151434191474),\n",
        " (u'Being an apartment manager sucks NSFL', 2139, 0.21380067581562942),\n",
        " (u'A husband and wife were sitting watching a TV program about psychology',\n",
        "  1222,\n",
        "  0.19427202941607663),\n",
        " (u'Do snakes have a fixed number of vertebrae from birth',\n",
        "  1195,\n",
        "  0.18001105148930352)]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_table['max_cosine'] = big_table['title'].map(lambda x: 0)\n",
      "big_table['avg_cosine'] = big_table['title'].map(lambda x: 0)\n",
      "big_table['min_cosine'] = big_table['title'].map(lambda x: 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key, value in big_table.iterrows():\n",
      "    max_score = 0\n",
      "    mean_score = 0\n",
      "    min_score = 0\n",
      "    try:\n",
      "        tuple_list = knearest(value['title'])\n",
      "        max_score = max(tuple_list,key=lambda item:item[1])[1]\n",
      "        min_score = min(tuple_list,key=lambda item:item[1])[1]\n",
      "        mean_score =  np.mean([a[1] for a in tuple_list] )\n",
      "    except:\n",
      "        pass\n",
      "        \n",
      "    big_table['max_cosine'][key] = max_score\n",
      "    big_table['avg_cosine'][key] = mean_score\n",
      "    big_table['min_cosine'][key] = min_score\n",
      "    \n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"max cosine pearson\"\n",
      "r_row, p_value = pearsonr(big_table['max_cosine'], big_table['score'])\n",
      "print \"Pearson coefficient is\" + str(r_row) + \" with a p-value of \" + str(p_value)\n",
      "\n",
      "print \"avg cosine pearson\"\n",
      "r_row, p_value = pearsonr(big_table['avg_cosine'], big_table['score'])\n",
      "print \"Pearson coefficient is\" + str(r_row) + \" with a p-value of \" + str(p_value)\n",
      "\n",
      "print \"min cosine pearson\"\n",
      "r_row, p_value = pearsonr(big_table['min_cosine'], big_table['score'])\n",
      "print \"Pearson coefficient is\" + str(r_row) + \" with a p-value of \" + str(p_value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "max cosine pearson\n",
        "Pearson coefficient is0.0337054209798 with a p-value of 5.47096797985e-08\n",
        "avg cosine pearson\n",
        "Pearson coefficient is0.0384110732175 with a p-value of 5.84204004251e-10\n",
        "min cosine pearson\n",
        "Pearson coefficient is0.00743062895858 with a p-value of 0.230945244792\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}